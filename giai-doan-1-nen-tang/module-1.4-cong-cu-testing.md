# MODULE 1.4: CÃ”NG Cá»¤ TESTING & Ká»¸ NÄ‚NG TESTER

**Giai Ä‘oáº¡n**: 1 - Ná»n táº£ng
**Thá»i lÆ°á»£ng há»c**: 3-4 giá»
**Äá»™ khÃ³**: â­ Dá»…

---

## Má»¤C TIÃŠU Há»ŒC Táº¬P (Learning Objectives)

Sau khi hoÃ n thÃ nh module nÃ y, báº¡n sáº½ cÃ³ thá»ƒ:

### FL-1.5.1 (K2) - Explain generic skills required for testing
**Giáº£i thÃ­ch Ä‘Æ°á»£c cÃ¡c ká»¹ nÄƒng chung cáº§n cÃ³ cho testing**

### FL-1.5.2 (K1) - Recall benefits of whole team approach
**Nhá»› láº¡i Ä‘Æ°á»£c lá»£i Ã­ch cá»§a whole team approach**

### FL-1.5.3 (K2) - Distinguish benefits of independence of testing
**PhÃ¢n biá»‡t Ä‘Æ°á»£c lá»£i Ã­ch cá»§a independence trong testing**

### FL-6.1.1 (K1) - Recall types of test tools
**Nhá»› láº¡i Ä‘Æ°á»£c cÃ¡c loáº¡i test tools**

### FL-6.2.1 (K2) - Explain benefits and risks of test automation
**Giáº£i thÃ­ch Ä‘Æ°á»£c lá»£i Ã­ch vÃ  rá»§i ro cá»§a test automation**

**Business Outcomes**: FL-BO11, FL-BO12

---

## PHáº¦N 1: Ká»¸ NÄ‚NG Cáº¦N THIáº¾T CHO TESTER

### 1.1. Generic Skills (Ká»¹ nÄƒng chung)

#### 1. Testing Knowledge (Kiáº¿n thá»©c Testing)
**MÃ´ táº£**: Hiá»ƒu biáº¿t vá» testing principles, techniques, vÃ  processes

**Bao gá»“m**:
- Test design techniques (EP, BVA, State Transition, etc.)
- Test levels vÃ  types
- SDLC models
- Defect lifecycle
- Test management

**VÃ­ dá»¥ Ã¡p dá»¥ng**:
```
Scenario: Testing login form

Kiáº¿n thá»©c cáº§n:
âœ“ EP/BVA: Design test cases cho email vÃ  password fields
âœ“ Security testing: Check SQL injection, XSS
âœ“ Usability: Verify error messages clear
âœ“ Performance: Check login response time
```

---

#### 2. Thoroughness (TÃ­nh tá»‰ má»‰, cáº©n tháº­n)
**MÃ´ táº£**: ChÃº Ã½ Ä‘áº¿n detail, khÃ´ng bá» sÃ³t

**Quan trá»ng vÃ¬**:
- Má»™t detail nhá» bá»‹ bá» qua cÃ³ thá»ƒ lÃ  critical bug
- Test cases cáº§n cover all scenarios
- Defect reports cáº§n chi tiáº¿t Ä‘á»ƒ developers reproduce

**VÃ­ dá»¥**:
```
KHÃ”NG tá»‰ má»‰:
"Login khÃ´ng work"

Tá»ˆ Má»ˆ:
"Login fails vá»›i email 'test@example.com' vÃ 
password 'Pass123!' khi click 'Login' button.
Error: 'Invalid credentials'
Expected: Login successful
Browser: Chrome 118.0, Windows 11
Reproducible: 100%"
```

---

#### 3. Good Communication (Giao tiáº¿p tá»‘t)
**MÃ´ táº£**: Communicate rÃµ rÃ ng, hiá»‡u quáº£ vá»›i team

**Cáº§n giao tiáº¿p vá»›i**:
- **Developers**: Giáº£i thÃ­ch bugs, clarify requirements
- **Product Owners**: Update progress, discuss priorities
- **Test Manager**: Report status, request resources
- **End users**: Conduct UAT, gather feedback

**VÃ­ dá»¥ tÃ¬nh huá»‘ng**:
```
BAD Communication:
"CÃ¡i nÃ y bá»‹ lá»—i rá»“i, fix Ä‘i!"
â†’ Developer khÃ´ng hiá»ƒu, frustration

GOOD Communication:
"Hi [Dev name], tÃ´i tháº¥y khi user click 'Submit'
vá»›i empty name field, app crash thay vÃ¬ show
validation error. CÃ³ thá»ƒ báº¡n check logic validation?
TÃ´i Ä‘Ã£ log bug BUG-123 vá»›i steps chi tiáº¿t."
â†’ Developer hiá»ƒu rÃµ, collaborate tá»‘t
```

---

#### 4. Analytical Thinking (TÆ° duy phÃ¢n tÃ­ch)
**MÃ´ táº£**: PhÃ¢n tÃ­ch problems, tÃ¬m root causes, identify patterns

**Ãp dá»¥ng vÃ o**:
- Analyze requirements Ä‘á»ƒ identify test conditions
- Debug failures Ä‘á»ƒ find root causes
- Analyze defect trends Ä‘á»ƒ identify problem areas

**VÃ­ dá»¥**:
```
Situation: 5 bugs found trong Payment module

ANALYSIS:
Pattern: Táº¥t cáº£ bugs related to decimal calculations
Root cause: Floating-point precision issue
Action: Suggest sá»­ dá»¥ng decimal type thay vÃ¬ float
Impact: Prevent similar bugs in future
```

---

#### 5. Technical Knowledge (Kiáº¿n thá»©c ká»¹ thuáº­t)
**MÃ´ táº£**: Hiá»ƒu technical aspects cá»§a test object

**TÃ¹y context, cáº§n biáº¿t**:
- **Web testing**: HTML, CSS, JavaScript, HTTP, APIs
- **Mobile testing**: iOS/Android, mobile-specific issues
- **Database testing**: SQL, database concepts
- **API testing**: REST, JSON, XML, authentication
- **Performance testing**: Load concepts, bottlenecks

**Level cáº§n thiáº¿t**:
- **Manual tester**: Basic understanding
- **Automation tester**: Programming skills (JavaScript, Python, Java)
- **Performance tester**: Deep understanding cá»§a architecture

**VÃ­ dá»¥**:
```
Web App Testing cáº§n biáº¿t:
âœ“ HTTP status codes (200, 404, 500, etc.)
âœ“ Cookies, Sessions, Local Storage
âœ“ Browser DevTools (Network, Console)
âœ“ Basic JavaScript debugging
âœ“ API concepts (GET, POST, PUT, DELETE)
```

---

#### 6. Domain Knowledge (Kiáº¿n thá»©c nghiá»‡p vá»¥)
**MÃ´ táº£**: Hiá»ƒu business domain cá»§a test object

**VÃ­ dá»¥ domains**:
- **Banking**: Interest calculations, transaction types
- **E-commerce**: Order flow, payment methods, shipping
- **Healthcare**: Patient records, compliance (HIPAA)
- **Education**: Enrollment, grading, curriculum

**GiÃ¡ trá»‹**:
```
WITHOUT Domain Knowledge:
- Test chá»‰ theo spec (cÃ³ thá»ƒ miss business logic errors)
- KhÃ³ communicate vá»›i business users

WITH Domain Knowledge:
- Identify business logic bugs (spec cÃ³ thá»ƒ sai)
- Better test case design (real-world scenarios)
- Effective communication vá»›i stakeholders
```

**Case Study**:
```
Domain: E-commerce Discount System

Domain Knowledge giÃºp tester biáº¿t:
âœ“ KhÃ´ng Ä‘Æ°á»£c combine multiple percentage discounts
âœ“ Free shipping khÃ´ng apply vá»›i remote areas
âœ“ Flash sale price priority hÆ¡n member discount
âœ“ Refund cáº§n trá»« shipping fee Ä‘Ã£ sá»­ dá»¥ng

â†’ Design test cases cover business rules nÃ y!
```

---

### 1.2. Soft Skills

#### 1. Curiosity (TÃ² mÃ²)
**MÃ´ táº£**: LuÃ´n há»i "What if...?"

**VÃ­ dá»¥**:
```
Feature: Upload profile photo

Curious Tester asks:
- What if file size > 10MB?
- What if file format lÃ  .exe?
- What if filename cÃ³ special characters?
- What if user cancel during upload?
- What if network disconnect mid-upload?
- What if upload same file twice?

â†’ TÃ¬m ra nhiá»u edge cases hÆ¡n!
```

---

#### 2. Skepticism (HoÃ i nghi lÃ nh máº¡nh)
**MÃ´ táº£**: KhÃ´ng assume code works, verify everything

**VÃ­ dá»¥**:
```
Developer: "TÃ´i Ä‘Ã£ fix bug rá»“i, khÃ´ng cáº§n test láº¡i"

Skeptical Tester:
"Let me verify the fix..."
â†’ Tests â†’ Finds regression bug!

Lesson: Always verify, don't trust blindly
```

---

#### 3. Creativity (SÃ¡ng táº¡o)
**MÃ´ táº£**: Think outside the box, find unusual scenarios

**VÃ­ dá»¥**:
```
Standard Test: Enter email, password, click Login
Creative Test: Copy-paste 10,000 characters into password field
â†’ Found: UI breaks, app crashes!

Standard Test: Upload 1 photo
Creative Test: Upload 100 photos simultaneously
â†’ Found: Server timeout, no error handling!
```

---

#### 4. Attention to Detail (ChÃº Ã½ chi tiáº¿t)
**VÃ­ dá»¥**:
```
Tester notices:
- Button text: "Submi" (missing 't')
- Date format inconsistent: DD/MM vs MM/DD
- Error message has grammar mistake
- Loading icon doesn't center properly
- Minor UI alignment off by 2px

â†’ Polish product quality!
```

---

## PHáº¦N 2: WHOLE TEAM APPROACH

### 2.1. Äá»‹nh nghÄ©a

**Whole Team Approach**: Má»i team member chá»‹u trÃ¡ch nhiá»‡m quality, khÃ´ng chá»‰ testers.

### 2.2. Trong Agile

```
TRADITIONAL:
Developers â†’ Write code
Testers â†’ Test code
(Silos, handoffs, delays)

WHOLE TEAM APPROACH:
Developers + Testers + PO + Users â†’ Collaborate Ä‘á»ƒ ensure quality
(Shared responsibility)
```

### 2.3. Benefits

#### 1. Shared Responsibility
**Everyone cares about quality**

```
Developer:
- Write unit tests
- Review code
- Think about testability

Tester:
- Review requirements early
- Pair with developers
- Automate tests

PO:
- Write clear acceptance criteria
- Participate in demos
- Provide feedback quickly
```

---

#### 2. Better Communication
**Reduce misunderstandings**

```
Daily Standups:
- Developers share progress
- Testers share blockers
- PO clarifies requirements
- Quick decisions made

â†’ No "throw over the wall" mentality
```

---

#### 3. Faster Feedback
**Issues found vÃ  fixed nhanh hÆ¡n**

```
Developer finishes feature:
â†’ Pair with tester for quick check
â†’ Issues found immediately
â†’ Fix trong same day

vs.

Traditional:
Developer finishes â†’ Wait for testing phase
â†’ Tester tests after 2 weeks â†’ Finds issue
â†’ Developer already forgot code â†’ Takes long to fix
```

---

#### 4. Skill Sharing
**Team members learn from each other**

```
Developers teach testers:
- Code structure
- Technical debugging
- Automation frameworks

Testers teach developers:
- Test design techniques
- User perspective
- Quality mindset
```

---

### 2.4. VÃ­ dá»¥ thá»±c táº¿

```
USER STORY: "User can reset password via email"

WHOLE TEAM collaboration:

PO: Writes acceptance criteria (Given-When-Then)
Developer: Reviews AC, asks clarifications
Tester: Adds test scenarios PO missed
Designer: Reviews UX flow
Developer: Implements with unit tests
Tester: Pairs with dev for quick testing
Team: Demo together to stakeholders
Everyone: Retrospective to improve

Result: High quality, delivered fast
```

---

## PHáº¦N 3: INDEPENDENCE OF TESTING

### 3.1. Levels of Independence

```
LEVEL 1: No independent testing
â””â”€ Developers test their own code only

LEVEL 2: Testing by another team member
â””â”€ Developer A tests code cá»§a Developer B

LEVEL 3: Testing by dedicated test team
â””â”€ Separate test team trong cÃ¹ng organization

LEVEL 4: Testing by independent organization
â””â”€ Third-party testing company (outsource)
```

### 3.2. Benefits of Independence

#### 1. Objectivity
**KhÃ´ng bá»‹ bias bá»Ÿi code Ä‘Ã£ viáº¿t**

```
Developer tests own code:
- Might skip scenarios vÃ¬ "I know code works"
- Focus on happy path
- Miss edge cases

Independent tester:
- No assumptions
- Test thoroughly
- Find unexpected issues
```

---

#### 2. Different Perspective
**NhÃ¬n tá»« user perspective**

```
Developer perspective:
"Code executes without errors" âœ“

Tester perspective:
"Does it meet user needs?"
"Is UX intuitive?"
"Is error message helpful?"
```

---

#### 3. Challenge Assumptions
**Question everything**

```
Developer: "Users sáº½ khÃ´ng bao giá» lÃ m tháº¿"
Tester: "Let me test that scenario..."
â†’ Finds critical bug!
```

---

### 3.3. Drawbacks of Independence

#### 1. Communication Gap
```
Äá»™c láº­p quÃ¡ má»©c â†’ Lack of collaboration
â†’ Testers khÃ´ng hiá»ƒu technical constraints
â†’ Developers khÃ´ng hiá»ƒu testing challenges
```

#### 2. Us vs Them Mentality
```
Developers: "Testers luÃ´n complain"
Testers: "Developers write buggy code"
â†’ Blame game, not teamwork
```

#### 3. Cost
```
Independent test team hoáº·c outsource = Extra cost
```

---

### 3.4. Balance is Key

**IDEAL**: Combine independence with collaboration

```
âœ“ Dedicated testers (independence)
+ Whole team approach (collaboration)
= Best of both worlds

Example:
- Testers design test cases independently
- Developers write unit tests
- Testers vÃ  Developers pair for integration testing
- Daily collaboration in standups
- Shared responsibility for quality
```

---

## PHáº¦N 4: TEST TOOLS

### 4.1. Types of Test Tools

#### 1. Test Management Tools
**Purpose**: Quáº£n lÃ½ test process

**Examples**:
- **Jira** (vá»›i Zephyr/Xray plugin)
- **TestRail**
- **qTest**
- **Azure Test Plans**

**Features**:
```
âœ“ Manage test cases
âœ“ Plan test execution
âœ“ Track test results
âœ“ Generate reports
âœ“ Integrate vá»›i defect tracking
âœ“ Traceability matrix
```

---

#### 2. Static Testing Tools
**Purpose**: Analyze code/documents WITHOUT execution

**Examples**:
- **SonarQube**: Code quality analysis
- **ESLint**: JavaScript linting
- **Grammarly**: Document review
- **Checkstyle**: Java code style

**What they find**:
```
âœ“ Code smells
âœ“ Code complexity
âœ“ Coding standard violations
âœ“ Duplicate code
âœ“ Security vulnerabilities (static)
âœ“ Documentation issues
```

---

#### 3. Test Design & Implementation Tools
**Purpose**: Help design vÃ  implement tests

**Examples**:
- **Selenium IDE**: Record/playback web tests
- **Katalon Studio**: Test automation platform
- **Postman**: API testing
- **Cucumber**: BDD framework

**Features**:
```
âœ“ Generate test cases from models
âœ“ Record user actions
âœ“ Create test data
âœ“ Design test procedures
```

---

#### 4. Test Execution & Coverage Tools
**Purpose**: Execute tests vÃ  measure coverage

**Examples**:
- **Selenium WebDriver**: Web automation
- **Cypress**: Modern web testing
- **Appium**: Mobile automation
- **JUnit/TestNG**: Unit testing frameworks
- **Istanbul/JaCoCo**: Code coverage

**Features**:
```
âœ“ Execute automated tests
âœ“ Capture screenshots/videos
âœ“ Measure code coverage
âœ“ Generate execution reports
âœ“ Integrate vá»›i CI/CD
```

---

#### 5. Non-Functional Testing Tools
**Purpose**: Test performance, security, etc.

**Performance Testing**:
- **JMeter**: Load testing
- **Gatling**: Performance testing
- **LoadRunner**: Enterprise load testing
- **k6**: Modern load testing

**Security Testing**:
- **OWASP ZAP**: Security scanning
- **Burp Suite**: Penetration testing
- **Nessus**: Vulnerability scanner

**Features**:
```
PERFORMANCE:
âœ“ Simulate concurrent users
âœ“ Measure response times
âœ“ Identify bottlenecks
âœ“ Generate load reports

SECURITY:
âœ“ Scan for vulnerabilities
âœ“ SQL injection testing
âœ“ XSS testing
âœ“ Security audit reports
```

---

#### 6. DevOps Tools
**Purpose**: Support CI/CD vÃ  continuous testing

**Examples**:
- **Jenkins**: CI/CD automation
- **GitLab CI**: Integrated CI/CD
- **GitHub Actions**: Workflow automation
- **Docker**: Containerization
- **Kubernetes**: Orchestration

**Use in Testing**:
```
Pipeline:
1. Code commit â†’ Git
2. Trigger build â†’ Jenkins
3. Run unit tests â†’ JUnit
4. Run integration tests â†’ Selenium
5. Run security scan â†’ OWASP ZAP
6. Deploy to test environment â†’ Docker
7. Run smoke tests â†’ Cypress
8. Generate report â†’ Allure

â†’ Automated, fast feedback!
```

---

#### 7. Collaboration Tools
**Purpose**: Team communication vÃ  collaboration

**Examples**:
- **Slack**: Team messaging
- **Microsoft Teams**: Collaboration platform
- **Confluence**: Documentation
- **Miro**: Visual collaboration

---

### 4.2. Tool Support for Testing - Summary Table

| Tool Category | Purpose | Examples | When to Use |
|---------------|---------|----------|-------------|
| **Test Management** | Organize tests | Jira, TestRail | All projects |
| **Static Testing** | Code analysis | SonarQube, ESLint | During development |
| **Test Automation** | Execute tests | Selenium, Cypress | Regression testing |
| **API Testing** | Test APIs | Postman, RestAssured | API projects |
| **Performance** | Load testing | JMeter, Gatling | High-traffic systems |
| **Security** | Security scan | OWASP ZAP, Burp | All web apps |
| **CI/CD** | Automation pipeline | Jenkins, GitLab CI | DevOps projects |
| **Collaboration** | Team work | Slack, Confluence | All teams |

---

## PHáº¦N 5: TEST AUTOMATION

### 5.1. Benefits of Test Automation

#### 1. Time Savings (Tiáº¿t kiá»‡m thá»i gian)
```
Manual Regression: 40 hours (1 person Ã— 40 hours)
Automated Regression: 2 hours execution

Repeat 10 times:
Manual: 400 hours
Automated: 20 hours + setup time

â†’ Saves 380+ hours!
```

---

#### 2. Consistency (Nháº¥t quÃ¡n)
```
Manual Test:
- Human errors possible
- Different testers â†’ Different results
- Boredom â†’ Missed steps

Automated Test:
- Exact same steps every time
- No human errors
- 100% reproducible
```

---

#### 3. Reusability (TÃ¡i sá»­ dá»¥ng)
```
Once automated:
âœ“ Run multiple times
âœ“ Run on different environments
âœ“ Run on different browsers
âœ“ Run on different OS
âœ“ Integrate to CI/CD

ROI = High!
```

---

#### 4. Faster Feedback
```
Commit code â†’ CI trigger â†’ Tests run â†’ Results in 15 minutes
vs.
Commit code â†’ Wait for tester â†’ Manual test â†’ Results next day
```

---

#### 5. Better Coverage
```
Automation can test:
âœ“ 1000s of combinations
âœ“ Large data sets
âœ“ Concurrent users (performance)
âœ“ Long-running tests (endurance)

Manual: Too time-consuming
```

---

#### 6. Enables CI/CD
```
Continuous Deployment requires:
â†’ Fast automated testing
â†’ Immediate feedback
â†’ Confidence to deploy

Manual testing = Too slow for CD
```

---

### 5.2. Risks of Test Automation

#### 1. Unrealistic Expectations
**Risk**: "Automate everything!"

```
REALITY:
- Not all tests should be automated
- Setup takes time (weeks/months)
- Maintenance effort needed
- Still need manual exploratory testing

SOLUTION:
- Automate high-value tests (regression, smoke)
- Keep some manual tests (usability, ad-hoc)
- Set realistic goals
```

---

#### 2. Inaccurate Estimates
**Risk**: Underestimate effort

```
COMMON MISTAKE:
"Writing automation script = 1 hour"

REALITY:
- Initial script: 1 hour
- Make it robust: 3 hours
- Handle edge cases: 2 hours
- Maintenance over time: ongoing
- Total: Much more!

SOLUTION:
- Factor in maintenance
- Budget for framework setup
- Account for learning curve
```

---

#### 3. Inappropriate Tool Use
**Risk**: Sá»­ dá»¥ng tool khÃ´ng phÃ¹ há»£p

```
BAD:
- Selenium for API testing (dÃ¹ng Postman!)
- Manual testing for performance (dÃ¹ng JMeter!)
- Over-automation (automate trivial tests)

GOOD:
- Right tool for right job
- Cost-benefit analysis
- Consider maintenance effort
```

---

#### 4. Over-Reliance on Automation
**Risk**: NghÄ© automation = No manual testing needed

```
DANGER:
"We have automation, khÃ´ng cáº§n manual testing"
â†’ Miss UX issues
â†’ Miss exploratory findings
â†’ Miss usability problems

BALANCE:
Automation: Regression, Repetitive tests
Manual: Exploratory, Usability, New features
```

---

#### 5. Tool Vendor Lock-in
**Risk**: Depend quÃ¡ nhiá»u vÃ o commercial tool

```
PROBLEM:
- Tool license expensive
- Vendor discontinues product
- Hard to migrate to another tool

MITIGATION:
- Use open-source when possible
- Design framework tool-agnostic
- Evaluate vendor stability
```

---

#### 6. Compatibility Issues
**Risk**: Scripts break khi environment changes

```
EXAMPLE:
- Browser update â†’ Selenium scripts fail
- API version change â†’ Tests break
- UI redesign â†’ Locators invalid

SOLUTION:
- Robust locator strategies
- Version control for test code
- CI pipeline catches breaks early
- Regular maintenance schedule
```

---

### 5.3. When to Automate vs Manual

#### Automate GOOD for:
```
âœ“ Regression tests (run repeatedly)
âœ“ Smoke tests (run after every build)
âœ“ Data-driven tests (many combinations)
âœ“ Performance tests (load, stress)
âœ“ API tests (fast, stable)
âœ“ Repetitive tests (same steps)
```

#### Manual BETTER for:
```
âœ“ Exploratory testing
âœ“ Usability testing
âœ“ Ad-hoc testing
âœ“ Tests that change frequently
âœ“ One-time tests
âœ“ Visual design verification
```

---

## PHáº¦N 6: PRACTICE QUESTIONS

### Question 1 (K2)
Which of the following is a benefit of independent testing?

A. Independent testers find different types of defects than developers
B. Independent testing is cheaper than testing by developers
C. Independent testers do not need to communicate with the development team
D. Independent testing eliminates the need for developers to test their own code

**ÄÃ¡p Ã¡n**: A
**Giáº£i thÃ­ch**: Independent testers bring different perspective vÃ  find different defects. B, C, D Ä‘á»u sai.

---

### Question 2 (K1)
Which skill is MOST important for a tester?

A. Ability to write code
B. Attention to detail
C. Knowledge of test tools
D. Ability to manage projects

**ÄÃ¡p Ã¡n**: B
**Giáº£i thÃ­ch**: Attention to detail lÃ  fundamental skill. A, C helpful nhÆ°ng khÃ´ng báº¯t buá»™c. D lÃ  test manager skill.

---

### Question 3 (K2)
Which of the following is a benefit of test automation?

A. All testing can be automated
B. Automation eliminates the need for manual testing
C. Automated tests can be run frequently with minimal effort
D. Automated testing is cheaper than manual testing for all types of tests

**ÄÃ¡p Ã¡n**: C
**Giáº£i thÃ­ch**: Automated tests cÃ³ thá»ƒ run nhiá»u láº§n vá»›i minimal effort. A, B, D Ä‘á»u sai.

---

### Question 4 (K1)
Which type of tool would be used to measure the percentage of code executed by automated tests?

A. Test management tool
B. Test execution tool
C. Coverage measurement tool
D. Static analysis tool

**ÄÃ¡p Ã¡n**: C
**Giáº£i thÃ­ch**: Coverage measurement tools (nhÆ° JaCoCo, Istanbul) measure code coverage.

---

### Question 5 (K2)
What is a risk of test automation?

A. It requires no maintenance once implemented
B. It can lead to over-reliance on automated testing
C. It eliminates the need for test planning
D. It is always more cost-effective than manual testing

**ÄÃ¡p Ã¡n**: B
**Giáº£i thÃ­ch**: Over-reliance on automation lÃ  risk. A, C, D Ä‘á»u sai.

---

## SELF-ASSESSMENT CHECKLIST

- [ ] TÃ´i cÃ³ thá»ƒ liá»‡t kÃª 5 generic skills cáº§n cho tester
- [ ] TÃ´i hiá»ƒu whole team approach vÃ  benefits
- [ ] TÃ´i phÃ¢n biá»‡t Ä‘Æ°á»£c levels of independence
- [ ] TÃ´i nhá»› Ä‘Æ°á»£c 7 types of test tools
- [ ] TÃ´i cÃ³ thá»ƒ giáº£i thÃ­ch benefits vÃ  risks cá»§a automation
- [ ] TÃ´i biáº¿t khi nÃ o nÃªn automate vs manual test

**Äáº¡t â‰¥5/6** â†’ HoÃ n thÃ nh Giai Ä‘oáº¡n 1!

---

## KEY TAKEAWAYS

1. **Generic Skills**: Testing knowledge, Thoroughness, Communication, Analytical thinking, Technical knowledge, Domain knowledge
2. **Whole Team Approach**: Shared responsibility, Better communication, Faster feedback
3. **Independence**: Brings objectivity nhÆ°ng cáº§n balance vá»›i collaboration
4. **Test Tools**: 7 categories - Management, Static, Design, Execution, Non-functional, DevOps, Collaboration
5. **Automation**: Benefits (time savings, consistency) vs Risks (unrealistic expectations, maintenance)
6. **Balance**: Automate regression/repetitive, Manual cho exploratory/usability

---

## CONGRATULATIONS! ğŸ‰

Báº¡n Ä‘Ã£ hoÃ n thÃ nh **GIAI ÄOáº N 1: Ná»€N Táº¢NG**!

### Báº¡n Ä‘Ã£ há»c Ä‘Æ°á»£c:
- âœ“ Testing lÃ  gÃ¬ vÃ  táº¡i sao quan trá»ng
- âœ“ 7 Testing Principles
- âœ“ Error â†’ Defect â†’ Failure
- âœ“ 7 Test Activities
- âœ“ Testware vÃ  Traceability
- âœ“ Test Roles
- âœ“ Ká»¹ nÄƒng cáº§n thiáº¿t
- âœ“ Test Tools vÃ  Automation

### Tiáº¿p theo:
ğŸ“ **BÃ€I Táº¬P**: [BÃ i táº­p Giai Ä‘oáº¡n 1](bai-tap-giai-doan-1.md) - Cá»§ng cá»‘ kiáº¿n thá»©c
ğŸ“š **MODULE TIáº¾P**: [Giai Ä‘oáº¡n 2: Static Testing](../giai-doan-2-static-testing/module-2.1-static-testing-co-ban.md)

**Thá»i gian nghá»‰**: 1 ngÃ y trÆ°á»›c khi lÃ m bÃ i táº­p
**Thá»i gian Ã´n**: 1 giá» review táº¥t cáº£ modules cá»§a Giai Ä‘oáº¡n 1

---

**Tá»•ng thá»i gian Giai Ä‘oáº¡n 1**: 14-18 giá»
